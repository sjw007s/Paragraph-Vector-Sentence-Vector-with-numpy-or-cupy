{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run ../chap15/NLP.ipynb\n",
    "%run ../chap15/NLP_dataset.ipynb\n",
    "np.random.seed(int(time.time()))\n",
    "#np.random.seed(1)\n",
    "epoch_count=700\n",
    "batch_size=2500\n",
    "learning_rate=0.005\n",
    "learning_decrease=1\n",
    "restore_='result_test.csv'\n",
    "\n",
    "conf1 = [['full', {'width':300}]]\n",
    "for i in range(1,2,1):\n",
    "    restore_temp=restore_[:-4]+str(i)+restore_[-4:]\n",
    "    vsm1 = NLP('vsm1', \"dsf\", conf1,JJ=1/i,word_vector_dimension=200, window_size=5,negative=1,load=0)\n",
    "    vsm1.train(epoch_count=epoch_count, batch_size=batch_size, \n",
    "                            learning_rate=learning_rate,learning_decrease=learning_decrease,restore=restore_temp, name=\"training_text\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1688 6\n",
      "1: full, 2200=>[300] pm:2200x300+300=660300\n",
      "Total parameter count: 660300\n",
      "the number of words and the number of unique words\n",
      "6 511\n",
      "loss: 0.69040334\n",
      "loss: 0.6957409\n",
      "0.019841146\n",
      "loss: 0.6906697\n",
      "loss: 0.6965977\n",
      "-0.011268418\n",
      "loss: 0.6921584\n",
      "loss: 0.6940282\n",
      "0.022043262\n",
      "loss: 0.6925508\n",
      "loss: 0.69373924\n",
      "0.01830629\n",
      "loss: 0.692375\n",
      "loss: 0.69388855\n",
      "0.01533598\n",
      "loss: 0.6924463\n",
      "loss: 0.693864\n",
      "0.017753964\n",
      "loss: 0.69265157\n",
      "loss: 0.69376814\n",
      "0.052080244\n",
      "loss: 0.69296485\n",
      "loss: 0.6933412\n",
      "0.06031496\n",
      "loss: 0.69308674\n",
      "loss: 0.69320804\n",
      "0.06176404\n",
      "loss: 0.69306076\n",
      "loss: 0.6932353\n",
      "0.05990446\n",
      "loss: 0.69306046\n",
      "loss: 0.69323456\n",
      "0.05946264\n",
      "loss: 0.6931256\n",
      "loss: 0.69316757\n",
      "0.0553414\n",
      "loss: 0.6930943\n",
      "loss: 0.69320047\n",
      "0.053375445\n",
      "loss: 0.6930481\n",
      "loss: 0.6932491\n",
      "0.05265965\n",
      "loss: 0.6931209\n",
      "loss: 0.69317377\n",
      "0.052549843\n",
      "loss: 0.6931142\n",
      "loss: 0.69317657\n",
      "0.05431184\n",
      "loss: 0.69311124\n",
      "loss: 0.6931845\n",
      "0.0561523\n",
      "loss: 0.69305646\n",
      "loss: 0.69326204\n",
      "0.068957485\n",
      "loss: 0.692972\n",
      "loss: 0.6933258\n",
      "0.110619806\n",
      "loss: 0.6931163\n",
      "loss: 0.6931793\n",
      "0.12750037\n",
      "loss: 0.6931213\n",
      "loss: 0.6931752\n",
      "0.13368177\n",
      "loss: 0.69301397\n",
      "loss: 0.69329464\n",
      "0.14464374\n",
      "loss: 0.6929645\n",
      "loss: 0.6933246\n",
      "0.14976294\n",
      "loss: 0.69309187\n",
      "loss: 0.6932039\n",
      "0.15155801\n",
      "loss: 0.69313616\n",
      "loss: 0.69316006\n",
      "0.15219422\n",
      "loss: 0.6930869\n",
      "loss: 0.6932066\n",
      "0.15246795\n",
      "loss: 0.6931452\n",
      "loss: 0.693149\n",
      "0.1532161\n",
      "loss: 0.69314015\n",
      "loss: 0.6931547\n",
      "0.15359533\n",
      "loss: 0.69314307\n",
      "loss: 0.69315165\n",
      "0.15372415\n",
      "loss: 0.6930767\n",
      "loss: 0.69322693\n",
      "0.15376918\n",
      "loss: 0.6930978\n",
      "loss: 0.6931955\n",
      "0.15351197\n",
      "loss: 0.69312376\n",
      "loss: 0.6931713\n",
      "0.15188734\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15130417\n",
      "loss: 0.6931467\n",
      "loss: 0.6931479\n",
      "0.15109639\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.1510226\n",
      "loss: 0.6931463\n",
      "loss: 0.69314855\n",
      "0.15099637\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15098709\n",
      "loss: 0.6931253\n",
      "loss: 0.69316953\n",
      "0.1510161\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15107206\n",
      "loss: 0.69308835\n",
      "loss: 0.6932023\n",
      "0.15119976\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15184158\n",
      "loss: 0.6931413\n",
      "loss: 0.69315374\n",
      "0.15205555\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15211391\n",
      "loss: 0.69313896\n",
      "loss: 0.6931557\n",
      "0.15213451\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15214178\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15214434\n",
      "loss: 0.69310075\n",
      "loss: 0.6931945\n",
      "0.15228057\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15307501\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15335406\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15345241\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.1534871\n",
      "loss: 0.69312674\n",
      "loss: 0.6931675\n",
      "0.15349941\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.1535037\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15350525\n",
      "loss: 0.69314677\n",
      "loss: 0.69314796\n",
      "0.15350577\n",
      "loss: 0.6931416\n",
      "loss: 0.69315314\n",
      "0.15354818\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.1536227\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15364894\n",
      "loss: 0.69314194\n",
      "loss: 0.69315284\n",
      "0.15369777\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15377073\n",
      "loss: 0.6931337\n",
      "loss: 0.6931611\n",
      "0.15384048\n",
      "loss: 0.69313663\n",
      "loss: 0.6931581\n",
      "0.15413395\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15437596\n",
      "loss: 0.6931448\n",
      "loss: 0.6931499\n",
      "0.15446109\n",
      "loss: 0.6931454\n",
      "loss: 0.6931493\n",
      "0.15449105\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15450163\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15450531\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15450667\n",
      "loss: 0.6931376\n",
      "loss: 0.69315714\n",
      "0.1545071\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15450726\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.1545073\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15450731\n",
      "loss: 0.6931408\n",
      "loss: 0.6931539\n",
      "0.15453282\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15468292\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15473579\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15475428\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15476084\n",
      "loss: 0.6931408\n",
      "loss: 0.693154\n",
      "0.15479712\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.1549945\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15506387\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.1550882\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.1550968\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15509982\n",
      "loss: 0.69314474\n",
      "loss: 0.69315\n",
      "0.15511113\n",
      "loss: 0.6931434\n",
      "loss: 0.6931513\n",
      "0.15519229\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.1553335\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15538308\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15540053\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15540671\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15540883\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15540963\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15540989\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15540999\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15541\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15541\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15541\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15541\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15541\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15541\n",
      "loss: 0.69314724\n",
      "loss: 0.6931475\n",
      "0.15541084\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15541585\n",
      "loss: 0.6931457\n",
      "loss: 0.69314903\n",
      "0.1554379\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15555759\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.1555996\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15561439\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15561949\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15562133\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15562198\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15562217\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15562227\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15562229\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15562229\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15562229\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15562229\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15562229\n",
      "loss: 0.6931472\n",
      "loss: 0.69314754\n",
      "0.15562388\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15563315\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.1556364\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15563756\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15563795\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15563807\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15563811\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15563813\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15563813\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15563813\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15563813\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15563813\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15563813\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15563813\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15563813\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15563813\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15563813\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15563813\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15563813\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15563813\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15563813\n",
      "loss: 0.69314736\n",
      "loss: 0.69314736\n",
      "0.15563813\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-90c7bcbc82b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mvsm1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNLP_Doc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'vsm1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"dsf\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconf1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mJJ\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mword_vector_dimension\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnegative\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentence_vector_dimension\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     vsm1.train(epoch_count=epoch_count, batch_size=batch_size, \n\u001b[1;32m---> 16\u001b[1;33m                             learning_rate=learning_rate,learning_decrease=learning_decrease,restore=restore_temp, name=\"training_text\")\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-0f4e0abf6cb1>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, epoch_count, batch_size, learning_rate, learning_decrease, restore, name)\u001b[0m\n\u001b[0;32m     47\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m                 \u001b[0mtrX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_train_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m                 \u001b[0mcost\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0maa\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-0f4e0abf6cb1>\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_training\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maux_nn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_neuralnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m         \u001b[0mG_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackprop_neuralnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maux_nn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-0f4e0abf6cb1>\u001b[0m in \u001b[0;36mforward_neuralnet\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m     98\u001b[0m             \u001b[0maux_layers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maux\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maux\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_end_embedding_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpm_hiddens\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0maux\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maux_layers\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-0f4e0abf6cb1>\u001b[0m in \u001b[0;36mforward_end_embedding_layer\u001b[1;34m(self, x, pm, y)\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m                 \u001b[0mtemp_number_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnp_arange_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnegative\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcounting_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_number_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m                     \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\cupy\\random\\sample.py\u001b[0m in \u001b[0;36mchoice\u001b[1;34m(a, size, replace, p)\u001b[0m\n\u001b[0;32m    194\u001b[0m     \"\"\"\n\u001b[0;32m    195\u001b[0m     \u001b[0mrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_random_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\cupy\\random\\generator.py\u001b[0m in \u001b[0;36mchoice\u001b[1;34m(self, a, size, replace, p)\u001b[0m\n\u001b[0;32m    979\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0ma_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    980\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'a and p must have same size'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 981\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    982\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'probabilities are not non-negative'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    983\u001b[0m             \u001b[0mp_sum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcupy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%run ../chap15/NLP_Doc.ipynb\n",
    "%run ../chap15/NLP_dataset.ipynb\n",
    "np.random.seed(int(time.time()))\n",
    "#np.random.seed(1)\n",
    "epoch_count=700\n",
    "batch_size=100\n",
    "learning_rate=0.005\n",
    "learning_decrease=1\n",
    "restore_='result_test.csv'\n",
    "\n",
    "conf1 = [['full', {'width':300}]]\n",
    "for i in range(1,2,1):\n",
    "    restore_temp=restore_[:-4]+str(i)+restore_[-4:]\n",
    "    vsm1 = NLP_Doc('vsm1', \"dsf\", conf1,JJ=1/i,word_vector_dimension=200, window_size=5,negative=1,load=0, sentence_vector_dimension=200)\n",
    "    vsm1.train(epoch_count=epoch_count, batch_size=batch_size, \n",
    "                            learning_rate=learning_rate,learning_decrease=learning_decrease,restore=restore_temp, name=\"training_text\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
